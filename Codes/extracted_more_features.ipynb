{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9669a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import pywt\n",
    "from scipy import signal\n",
    "# S = (4500000)/24/(2**23-1) #uV/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f6420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#closest stamp for 1 value\n",
    "def find_closest(arr, val):\n",
    "    idx = np.abs(arr - val).argmin()\n",
    "    return (arr[idx] , idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dbf904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#closest stamps for our dataset\n",
    "def closest_stamp_values(time_stamps,events):\n",
    "    closest_stamps_vals = np.zeros(len(events))\n",
    "    closest_stamps_ids = np.zeros(len(events)) \n",
    "    \n",
    "    event_labels = []\n",
    "    \n",
    "    for i in range(len(events)):\n",
    "        closest_stamps_vals[i] = find_closest(time_stamps, events[i,0])[0]\n",
    "        closest_stamps_ids[i] = find_closest(time_stamps, events[i,0])[1]\n",
    "        event_labels.append(events[i,1])\n",
    "    \n",
    "    return closest_stamps_vals, closest_stamps_ids, event_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc4dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_fixation_and_baseline(closest_stamps_ids,event_labels,eeg_data):\n",
    "    session_data =  np.random.randint(100000,900000,(250,250,8))\n",
    "    rc = 0 # row count \n",
    "    markers = []\n",
    "    for i,image in enumerate(closest_stamps_ids):\n",
    "        if event_labels[i] == 'red' or event_labels[i] == 'white':\n",
    "            for j in range(5):\n",
    "                if event_labels[i] == 'red':\n",
    "                    markers.append(0)\n",
    "                if event_labels[i] == 'white':\n",
    "                    markers.append(1)\n",
    "                for k in range(250):\n",
    "                    if int(closest_stamps_ids[i])+j*256+250 > eeg_data.shape[0]:\n",
    "                        break\n",
    "                    session_data[rc][k] = eeg_data[int(closest_stamps_ids[i])+j*256:int(closest_stamps_ids[i])+j*256+250][k]\n",
    "                rc = rc + 1            \n",
    "    rc = 0\n",
    "    return markers,session_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "084aa547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(session_data):\n",
    "    _mean = []\n",
    "    _std = []\n",
    "    _skewness = []\n",
    "    _kurtosis = []\n",
    "    _hjorth_activity = []\n",
    "    _hjorth_mobility = []\n",
    "    _hjorth_complexity = []\n",
    "    _a1 = []\n",
    "    _a2=  []\n",
    "    _a3 = []\n",
    "    _b1 = []\n",
    "    _b2 = []\n",
    "    _b3 = []\n",
    "    _c1 = []\n",
    "    _c2 = []\n",
    "    _c3 = []\n",
    "    _d1 = []\n",
    "    _d2 = []\n",
    "    _d3 = []\n",
    "    _e1 = []\n",
    "    _e2 = []\n",
    "    _e3 = []\n",
    "    _f1 = []\n",
    "    _f2 = []\n",
    "    _f3 = []\n",
    "    _g1 = []\n",
    "    _g2 = []\n",
    "    _g3 = []\n",
    "    _h1 = []\n",
    "    _h2 = []\n",
    "    _h3 = []\n",
    "    _bandpowers = []\n",
    "\n",
    "    for i in range(250):\n",
    "        _mean.append(np.mean(session_data[i], axis = 0))\n",
    "        _std.append(np.std(session_data[i], axis = 0))\n",
    "        _skewness.append(skew(session_data[i], axis = 0))\n",
    "        _kurtosis.append(kurtosis(session_data[i], axis = 0))\n",
    "        hjorth_activity,hjorth_mobility,hjorth_complexity = all_hjorth(session_data[i])\n",
    "        _hjorth_activity.append(hjorth_activity)\n",
    "        _hjorth_mobility.append(hjorth_mobility)\n",
    "        _hjorth_complexity.append(hjorth_complexity)\n",
    "        _wf = wavelet_features(session_data[i].T,8)\n",
    "     #   _a1.append(a1)\n",
    "     #   _a2.append(a2)\n",
    "     #   _a3.append(a3)\n",
    "     #   _b1.append(b1)\n",
    "     #   _b2.append(b2)\n",
    "     #   _b3.append(b3)\n",
    "    #    _c1.append(c1)\n",
    "    #    _c2.append(c2)\n",
    "    #    _c3.append(c3)\n",
    "     #   _d1.append(d1)\n",
    "     #   _d2.append(d2)\n",
    "     #   _d3.append(d3)\n",
    "     #   _e1.append(e1)\n",
    "     #   _e2.append(e2)\n",
    "    #    _e3.append(e3)\n",
    "     #   _f1.append(f1)\n",
    "     #   _f2.append(f2)\n",
    "    #    _f3.append(f3)\n",
    "    #    _g1.append(g1)\n",
    "    #    _g2.append(g2)\n",
    "    #    _g3.append(g3)\n",
    "     #   _h1.append(h1)\n",
    "     #   _h2.append(h2)\n",
    "    #    _h3.append(h3)\n",
    "        _bandpowers.append(bandpowers(session_data[i].T))\n",
    "               \n",
    "               \n",
    "    _mean = np.array(_mean)\n",
    "    _std = np.array(_std)\n",
    "    _skewness = np.array(_skewness)\n",
    "    _kurtosis = np.array(_kurtosis)\n",
    "    _hjorth_activity = np.array(_hjorth_activity)\n",
    "    _hjorth_mobility = np.array(_hjorth_mobility)\n",
    "    _hjorth_complexity = np.array(_hjorth_complexity)\n",
    "    _bandpowers = np.array(_bandpowers).reshape(250,16)\n",
    "    print(\"start\")\n",
    "    print(_mean.shape)\n",
    "    print(_std.shape)\n",
    "    print(_skewness.shape)\n",
    "    print(_kurtosis.shape)\n",
    "    print(_hjorth_activity.shape)\n",
    "    print(_hjorth_mobility.shape)\n",
    "    print(_hjorth_complexity.shape)\n",
    "    print( _bandpowers.shape)\n",
    " #   print(np.array(_a1).reshape(250,1).shape)\n",
    " #   print(np.array(_a2).reshape(250,1).shape)\n",
    " #    print(np.array(_a3).reshape(250,1).shape)\n",
    " #   print(np.array(_b1).reshape(250,1).shape)\n",
    "#    print(np.array(_b2).reshape(250,1).shape)\n",
    " #   print(np.array(_b3).reshape(250,1).shape)\n",
    " #   print(np.array(_c1).reshape(250,1).shape)\n",
    " #   print(np.array(_c2).reshape(250,1).shape)\n",
    " #   print(np.array(_c3).reshape(250,1).shape)\n",
    " #   print(np.array(_d1).reshape(250,1).shape)\n",
    " #   print(np.array(_d2).reshape(250,1).shape)\n",
    " #   print(np.array(_d3).reshape(250,1).shape)\n",
    " #   print(np.array(_e1).reshape(250,1).shape)\n",
    "  #  print(np.array(_e2).reshape(250,1).shape)\n",
    " #   print(np.array(_e3).reshape(250,1).shape)\n",
    " #   print(np.array(_f1).reshape(250,1).shape)\n",
    " #   print(np.array(_f2).reshape(250,1).shape)\n",
    " #   print(np.array(_f3).reshape(250,1).shape)\n",
    "  #  print(np.array(_g1).reshape(250,1).shape)\n",
    " #   print(np.array(_g2).reshape(250,1).shape)\n",
    " #   print(np.array(_g3).reshape(250,1).shape)\n",
    "  #  print(np.array(_h1).reshape(250,1).shape)\n",
    " #   print(np.array(_h2).reshape(250,1).shape)\n",
    "  #  print(np.array(_h3).reshape(250,1).shape)\n",
    "    print(\"end\")\n",
    "    stat_features = np.concatenate((_mean, _std, _skewness, _kurtosis,_hjorth_activity,_hjorth_mobility,_hjorth_complexity,_bandpowers),axis=1)        \n",
    "  #  stat_features = np.concatenate((_mean, _std, _skewness, _kurtosis,_hjorth_activity,_hjorth_mobility,_hjorth_complexity,np.array(_a1).reshape(250,1),np.array(_a2).reshape(250,1),np.array(_a3).reshape(250,1),np.array(_b1).reshape(250,1),np.array(_b2).reshape(250,1),np.array(_b3).reshape(250,1),np.array(_c1).reshape(250,1),np.array(_c2).reshape(250,1),np.array(_c3).reshape(250,1),np.array(_d1).reshape(250,1),np.array(_d2).reshape(250,1),np.array(_d3).reshape(250,1),np.array(_e1).reshape(250,1),np.array(_e2).reshape(250,1),np.array(_e3).reshape(250,1),np.array(_f1).reshape(250,1),np.array(_f2).reshape(250,1),np.array(_f3).reshape(250,1),np.array(_g1).reshape(250,1),np.array(_g2).reshape(250,1),np.array(_g3).reshape(250,1),np.array(_h1).reshape(250,1),np.array(_h2).reshape(250,1),np.array(_h3).reshape(250,1),_bandpowers),axis=1)\n",
    "  \n",
    "    return stat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ee47f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpowers(segment):\n",
    "    features = []\n",
    "    for i in range(len(segment)):\n",
    "        f,Psd = signal.welch(segment[i,:], 100)\n",
    "        power1 = 0\n",
    "        power2 = 0\n",
    "        f1 = []\n",
    "        for j in range(0,len(f)):\n",
    "            if(f[j]>=4 and f[j]<=13):\n",
    "                power1 += Psd[j]\n",
    "            if(f[j]>=14 and f[j]<=30):\n",
    "                power2 += Psd[j]\n",
    "        features.append(power1)\n",
    "        features.append(power2)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901752b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for all the 8 channels combined\n",
    "def all_hjorth(input):                     \n",
    "    new_input = input.T\n",
    "    all_hjorth_activity = []\n",
    "    all_hjorth_mobility = []\n",
    "    all_hjorth_complexity = []\n",
    "    for i in range(8):\n",
    "        hjorth_activity,hjorth_mobility,hjorth_complexity = hjorth(new_input[i].reshape(1,250))\n",
    "        all_hjorth_activity.append(hjorth_activity)\n",
    "        all_hjorth_mobility.append(hjorth_mobility)\n",
    "        all_hjorth_complexity.append(hjorth_complexity)\n",
    "        \n",
    "    return np.array(all_hjorth_activity), np.array(all_hjorth_mobility), np.array(all_hjorth_complexity)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c093285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 1 channel\n",
    "def hjorth(input):                                             \n",
    "    realinput = input\n",
    "    hjorth_activity = np.zeros(len(realinput))\n",
    "    hjorth_mobility = np.zeros(len(realinput))\n",
    "    hjorth_diffmobility = np.zeros(len(realinput))\n",
    "    hjorth_complexity = np.zeros(len(realinput))\n",
    "    diff_input = np.diff(realinput)\n",
    "    diff_diffinput = np.diff(diff_input)\n",
    "    k = 0\n",
    "    for j in realinput:\n",
    "        hjorth_activity[k] = np.var(j)\n",
    "        hjorth_mobility[k] = np.sqrt(np.var(diff_input[k])/hjorth_activity[k])\n",
    "        hjorth_diffmobility[k] = np.sqrt(np.var(diff_diffinput[k])/np.var(diff_input[k]))\n",
    "        hjorth_complexity[k] = hjorth_diffmobility[k]/hjorth_mobility[k]\n",
    "        k = k+1\n",
    "    return np.sum(hjorth_activity)/8, np.sum(hjorth_mobility)/8, np.sum(hjorth_complexity)/8                       #returning hjorth activity, hjorth mobility , hjorth complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a557f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### FUNCTION TO FIND WAVELET FEATURES#######\n",
    "\n",
    "def wavelet_features(epoch):\n",
    "    cA_values = []\n",
    "    cD_values = []\n",
    "    cA_mean = []\n",
    "    cA_std = []\n",
    "    cA_Energy =[]\n",
    "    cD_mean = []\n",
    "    cD_std = []\n",
    "    cD_Energy = []\n",
    "    Entropy_D = []\n",
    "    Entropy_A = []\n",
    "    wavelet_features = []\n",
    "    for i in range(len(epoch)):\n",
    "        cA,cD=pywt.dwt(epoch[i,:],'coif1')\n",
    "        cA_values.append(cA)\n",
    "        cD_values.append(cD)\t\t#calculating the coefficients of wavelet transform.\n",
    "    for x in range(len(epoch)):   \n",
    "        cA_Energy.append(abs(np.sum(np.square(cA_values[x]))))\n",
    "        wavelet_features.append(abs(np.sum(np.square(cA_values[x]))))\n",
    "        \n",
    "    for x in range(len(epoch)):      \n",
    "        cD_Energy.append(abs(np.sum(np.square(cD_values[x]))))\n",
    "        wavelet_features.append(abs(np.sum(np.square(cD_values[x]))))\n",
    "        \n",
    "    return wavelet_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6482cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autogressiveModelParametersBurg(labels):\n",
    "    feature = []\n",
    "    a1=[]\n",
    "    a2=[]\n",
    "    a3=[]\n",
    "    model_order = 3\n",
    "    for i in range(32):\n",
    "        AR, rho, ref = arburg(labels[i], model_order)\n",
    "        feature.append(AR);\n",
    "    for i in range(32):\n",
    "        a1.append(feature[i][0])\n",
    "        a2.append(feature[i][1])\n",
    "        a3.append(feature[i][2])\n",
    "        \n",
    "    \n",
    "    ar1=np.mean(a1).real\n",
    "    ar2=np.mean(a2).real \n",
    "    ar3=np.mean(a3).real\n",
    "    \n",
    "    br1=np.min(a1).real\n",
    "    br2=np.min(a2).real \n",
    "    br3=np.min(a3).real\n",
    "    \n",
    "    cr1=np.max(a1).real\n",
    "    cr2=np.max(a2).real \n",
    "    cr3=np.max(a3).real\n",
    "    \n",
    "    \n",
    "    \n",
    "    return ar1,ar2,ar3,br1,br2,br3,cr1,cr2,cr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88974bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test_for_sessions_together(root_path,I,J,K):\n",
    "    df_1 = pd.read_csv(root_path + str(I) + '\\\\trials.txt', header=4)\n",
    "    events_df_1 = pd.read_csv(root_path + str(I) + '\\\\events.txt', header=None)\n",
    "\n",
    "    df_2 = pd.read_csv(root_path + str(J) + '\\\\trials.txt', header=4)\n",
    "    events_df_2 = pd.read_csv(root_path + str(J) + '\\\\events.txt', header=None)\n",
    "\n",
    "    df_3 = pd.read_csv(root_path + str(K) + '\\\\trials.txt', header=4)\n",
    "    events_df_3 = pd.read_csv(root_path + str(K) + '\\\\events.txt', header=None)\n",
    "    \n",
    "    df_1 = df_1[[' EXG Channel 0', ' EXG Channel 1', ' EXG Channel 2', ' EXG Channel 3', ' EXG Channel 4', ' EXG Channel 5', ' EXG Channel 6', ' EXG Channel 7', ' Timestamp']]\n",
    "    df_2 = df_2[[' EXG Channel 0', ' EXG Channel 1', ' EXG Channel 2', ' EXG Channel 3', ' EXG Channel 4', ' EXG Channel 5', ' EXG Channel 6', ' EXG Channel 7', ' Timestamp']]\n",
    "    df_3 = df_3[[' EXG Channel 0', ' EXG Channel 1', ' EXG Channel 2', ' EXG Channel 3', ' EXG Channel 4', ' EXG Channel 5', ' EXG Channel 6', ' EXG Channel 7', ' Timestamp']]\n",
    "    \n",
    "    df_1 = df_1.rename(columns={\" EXG Channel 0\":\"Fp1\", \" EXG Channel 1\":\"Fp2\", \" EXG Channel 2\":\"C3\", \" EXG Channel 3\":\"C4\", \" EXG Channel 4\":\"P3\", \" EXG Channel 5\":\"P4\", \" EXG Channel 6\":\"O1\", \" EXG Channel 7\":\"O2\"})\n",
    "    df_2 = df_2.rename(columns={\" EXG Channel 0\":\"Fp1\", \" EXG Channel 1\":\"Fp2\", \" EXG Channel 2\":\"C3\", \" EXG Channel 3\":\"C4\", \" EXG Channel 4\":\"P3\", \" EXG Channel 5\":\"P4\", \" EXG Channel 6\":\"O1\", \" EXG Channel 7\":\"O2\"})\n",
    "    df_3 = df_3.rename(columns={\" EXG Channel 0\":\"Fp1\", \" EXG Channel 1\":\"Fp2\", \" EXG Channel 2\":\"C3\", \" EXG Channel 3\":\"C4\", \" EXG Channel 4\":\"P3\", \" EXG Channel 5\":\"P4\", \" EXG Channel 6\":\"O1\", \" EXG Channel 7\":\"O2\"})\n",
    "    \n",
    "    events_1 = events_df_1.to_numpy()\n",
    "    events_2 = events_df_2.to_numpy()\n",
    "    events_3 = events_df_3.to_numpy()\n",
    "   \n",
    "    data_1 = df_1.to_numpy()\n",
    "    data_2 = df_2.to_numpy()\n",
    "    data_3 = df_3.to_numpy()\n",
    "    \n",
    "    eeg_data_1 = data_1[:,:8]\n",
    "    eeg_data_2 = data_2[:,:8]\n",
    "    eeg_data_3 = data_3[:,:8]\n",
    "    \n",
    "    time_stamp_1 = data_1[:, 8]\n",
    "    time_stamp_2 = data_2[:, 8]\n",
    "    time_stamp_3 = data_3[:, 8]\n",
    "    \n",
    "    closest_stamps_vals_1 = np.zeros(len(events_1))\n",
    "    closest_stamps_ids_1 = np.zeros(len(events_1))\n",
    "\n",
    "    closest_stamps_vals_2 = np.zeros(len(events_2))\n",
    "    closest_stamps_ids_2 = np.zeros(len(events_2))\n",
    "\n",
    "    closest_stamps_vals_3 = np.zeros(len(events_3))\n",
    "    closest_stamps_ids_3 = np.zeros(len(events_3))\n",
    "\n",
    "\n",
    "    event_labels_1 = []\n",
    "    event_labels_2 = []\n",
    "    event_labels_3 = []\n",
    "\n",
    "    closest_stamps_vals_1, closest_stamps_ids_1, event_labels_1 = closest_stamp_values(time_stamp_1,events_1)\n",
    "    closest_stamps_vals_2, closest_stamps_ids_2, event_labels_2 = closest_stamp_values(time_stamp_2,events_2)\n",
    "    closest_stamps_vals_3, closest_stamps_ids_3, event_labels_3 = closest_stamp_values(time_stamp_3,events_3)\n",
    " \n",
    "    \n",
    "    print(len(closest_stamps_ids_1), len(event_labels_1),eeg_data_1.shape)\n",
    "    markers_1, session_data_1 = remove_fixation_and_baseline(closest_stamps_ids_1,event_labels_1,eeg_data_1)\n",
    "    markers_2, session_data_2 = remove_fixation_and_baseline(closest_stamps_ids_2,event_labels_2,eeg_data_2)\n",
    "    markers_3, session_data_3 = remove_fixation_and_baseline(closest_stamps_ids_3,event_labels_3,eeg_data_3)\n",
    "    \n",
    "   \n",
    "    \n",
    "    markers_1 = np.array(markers_1)\n",
    "    markers_2 = np.array(markers_2)\n",
    "    markers_3 = np.array(markers_3)\n",
    "    \n",
    "    stat_features_1 = extract_features(session_data_1)\n",
    "    stat_features_2 = extract_features(session_data_2)\n",
    "    stat_features_3 = extract_features(session_data_3)\n",
    "    \n",
    "    print(\"stat_features_\" +  str(I) + \" shape=\" + str(stat_features_1.shape))\n",
    "    print(\"stat_features_\" +  str(J) + \" shape=\" + str(stat_features_2.shape))\n",
    "    print(\"stat_features_\" +  str(K) + \" shape=\" + str(stat_features_3.shape))\n",
    "    final_features = np.concatenate((stat_features_1, stat_features_2, stat_features_3), axis = 0)\n",
    "    markers = np.concatenate((markers_1, markers_2, markers_3), axis=0)\n",
    "    \n",
    "    print(final_features.shape)\n",
    "    print(markers.shape)\n",
    "    print('...printing seassion_data_' + str(I) + ' accuracy.....................')\n",
    "    diff_models_accuracy_on_features(stat_features_1,markers_1)\n",
    "    print('\\n\\n\\n...printing seassion_data_' + str(J) + ' accuracy.....................')\n",
    "    diff_models_accuracy_on_features(stat_features_2,markers_2)\n",
    "    print('\\n\\n\\n...printing seassion_data_' + str(K) + ' accuracy.....................')\n",
    "    diff_models_accuracy_on_features(stat_features_3,markers_3)\n",
    "    \n",
    "    print('\\n\\n\\n\\n\\n\\n\\n...printing final_session_data_accuracy')\n",
    "    diff_models_accuracy_on_features(final_features,markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00ccb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_models_accuracy_on_features(final_features,markers):\n",
    "     \n",
    "    X_train, X_test, y_train, y_test = train_test_split(final_features, markers, test_size=0.3, random_state=42)\n",
    "\n",
    "    # SVM\n",
    "    svm_clf = make_pipeline(StandardScaler(), SVC(kernel = 'linear'))\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    y_pred = svm_clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print('Linear SVM Accuracy: ' + str(accuracy_score(y_test, y_pred)*100) + '%')\n",
    "\n",
    "\n",
    "    # SVM\n",
    "    svm2_clf = make_pipeline(StandardScaler(), SVC(kernel = 'rbf'))\n",
    "    svm2_clf.fit(X_train, y_train)\n",
    "    y_pred = svm2_clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print('RBF SVM Accuracy: ' + str(accuracy_score(y_test, y_pred)*100) + '%')\n",
    "\n",
    "\n",
    "    # RF\n",
    "    rf_clf = RandomForestClassifier()\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    y_pred = rf_clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print('RF Accuracy: ' + str(accuracy_score(y_test, y_pred)*100) + '%')\n",
    " \n",
    "    # LDA\n",
    "\n",
    "    lda_clf = LinearDiscriminantAnalysis()\n",
    "    lda_clf.fit(X_train, y_train)\n",
    "    y_pred = lda_clf.predict(X_test) \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print('LDA Accuracy: ' + str(accuracy_score(y_test, y_pred)*100) + '%')\n",
    "\n",
    "\n",
    "    # DT\n",
    "    dt_clf = DecisionTreeClassifier()\n",
    "    dt_clf = dt_clf.fit(X_train, y_train)\n",
    "    y_pred = dt_clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print('DT Accuracy: ' + str(accuracy_score(y_test, y_pred)*100) + '%')\n",
    " \n",
    "    # NB\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print('NB Accuracy: ' + str(accuracy_score(y_test, y_pred)*100) + '%')\n",
    "\n",
    "    # KNN\n",
    "    knn_clf = KNeighborsClassifier()\n",
    "    knn_clf = knn_clf.fit(X_train, y_train)\n",
    "    y_pred = knn_clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print('KNN Accuracy: ' + str(accuracy_score(y_test, y_pred)*100) + '%')\n",
    "\n",
    "\n",
    "    # GPC\n",
    "    gp_clf = GaussianProcessClassifier()\n",
    "    gp_clf = gp_clf.fit(X_train, y_train)\n",
    "    y_pred = gp_clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print('GPC Accuracy: ' + str(accuracy_score(y_test, y_pred)*100) + '%')\n",
    "\n",
    "   # AdaBoost\n",
    "    adb_clf = AdaBoostClassifier()\n",
    "    adb_clf = adb_clf.fit(X_train, y_train)\n",
    "    y_pred = adb_clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print('AdaBoost Accuracy: ' + str(accuracy_score(y_test, y_pred)*100) + '%')\n",
    "\n",
    "\n",
    "   # QDA\n",
    "    qda_clf = QuadraticDiscriminantAnalysis()\n",
    "    qda_clf = qda_clf.fit(X_train, y_train)\n",
    "    y_pred = qda_clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print('QDA Accuracy: ' + str(accuracy_score(y_test, y_pred)*100) + '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49770459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 102 (108582, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\scipy\\signal\\spectral.py:1966: UserWarning: nperseg = 256 is greater than input length  = 250, using nperseg = 250\n",
      "  .format(nperseg, input_length))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 16)\n",
      "end\n",
      "start\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 16)\n",
      "end\n",
      "start\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 16)\n",
      "end\n",
      "stat_features_1 shape=(250, 72)\n",
      "stat_features_2 shape=(250, 72)\n",
      "stat_features_3 shape=(250, 72)\n",
      "(750, 72)\n",
      "(750,)\n",
      "...printing seassion_data_1 accuracy.....................\n",
      "[[14 26]\n",
      " [ 7 28]]\n",
      "Linear SVM Accuracy: 56.00000000000001%\n",
      "[[14 26]\n",
      " [10 25]]\n",
      "RBF SVM Accuracy: 52.0%\n",
      "[[17 23]\n",
      " [13 22]]\n",
      "RF Accuracy: 52.0%\n",
      "[[18 22]\n",
      " [10 25]]\n",
      "LDA Accuracy: 57.333333333333336%\n",
      "[[22 18]\n",
      " [19 16]]\n",
      "DT Accuracy: 50.66666666666667%\n",
      "[[ 6 34]\n",
      " [ 1 34]]\n",
      "NB Accuracy: 53.333333333333336%\n",
      "[[21 19]\n",
      " [13 22]]\n",
      "KNN Accuracy: 57.333333333333336%\n",
      "[[40  0]\n",
      " [35  0]]\n",
      "GPC Accuracy: 53.333333333333336%\n",
      "[[19 21]\n",
      " [16 19]]\n",
      "AdaBoost Accuracy: 50.66666666666667%\n",
      "[[13 27]\n",
      " [ 3 32]]\n",
      "QDA Accuracy: 60.0%\n",
      "\n",
      "\n",
      "\n",
      "...printing seassion_data_2 accuracy.....................\n",
      "[[17 23]\n",
      " [17 18]]\n",
      "Linear SVM Accuracy: 46.666666666666664%\n",
      "[[ 0 40]\n",
      " [ 2 33]]\n",
      "RBF SVM Accuracy: 44.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19 21]\n",
      " [15 20]]\n",
      "RF Accuracy: 52.0%\n",
      "[[20 20]\n",
      " [21 14]]\n",
      "LDA Accuracy: 45.33333333333333%\n",
      "[[21 19]\n",
      " [16 19]]\n",
      "DT Accuracy: 53.333333333333336%\n",
      "[[ 1 39]\n",
      " [ 1 34]]\n",
      "NB Accuracy: 46.666666666666664%\n",
      "[[18 22]\n",
      " [15 20]]\n",
      "KNN Accuracy: 50.66666666666667%\n",
      "[[40  0]\n",
      " [35  0]]\n",
      "GPC Accuracy: 53.333333333333336%\n",
      "[[15 25]\n",
      " [19 16]]\n",
      "AdaBoost Accuracy: 41.333333333333336%\n",
      "[[21 19]\n",
      " [10 25]]\n",
      "QDA Accuracy: 61.33333333333333%\n",
      "\n",
      "\n",
      "\n",
      "...printing seassion_data_3 accuracy.....................\n",
      "[[24 16]\n",
      " [17 18]]\n",
      "Linear SVM Accuracy: 56.00000000000001%\n",
      "[[15 25]\n",
      " [16 19]]\n",
      "RBF SVM Accuracy: 45.33333333333333%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19 21]\n",
      " [14 21]]\n",
      "RF Accuracy: 53.333333333333336%\n",
      "[[17 23]\n",
      " [14 21]]\n",
      "LDA Accuracy: 50.66666666666667%\n",
      "[[23 17]\n",
      " [16 19]]\n",
      "DT Accuracy: 56.00000000000001%\n",
      "[[ 5 35]\n",
      " [ 4 31]]\n",
      "NB Accuracy: 48.0%\n",
      "[[21 19]\n",
      " [15 20]]\n",
      "KNN Accuracy: 54.666666666666664%\n",
      "[[40  0]\n",
      " [35  0]]\n",
      "GPC Accuracy: 53.333333333333336%\n",
      "[[18 22]\n",
      " [19 16]]\n",
      "AdaBoost Accuracy: 45.33333333333333%\n",
      "[[ 9 31]\n",
      " [ 7 28]]\n",
      "QDA Accuracy: 49.333333333333336%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "...printing final_session_data_accuracy\n",
      "[[41 70]\n",
      " [40 74]]\n",
      "Linear SVM Accuracy: 51.11111111111111%\n",
      "[[28 83]\n",
      " [34 80]]\n",
      "RBF SVM Accuracy: 48.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59 52]\n",
      " [61 53]]\n",
      "RF Accuracy: 49.77777777777778%\n",
      "[[62 49]\n",
      " [56 58]]\n",
      "LDA Accuracy: 53.333333333333336%\n",
      "[[57 54]\n",
      " [50 64]]\n",
      "DT Accuracy: 53.77777777777778%\n",
      "[[  4 107]\n",
      " [  3 111]]\n",
      "NB Accuracy: 51.11111111111111%\n",
      "[[69 42]\n",
      " [53 61]]\n",
      "KNN Accuracy: 57.77777777777777%\n",
      "[[111   0]\n",
      " [114   0]]\n",
      "GPC Accuracy: 49.333333333333336%\n",
      "[[61 50]\n",
      " [48 66]]\n",
      "AdaBoost Accuracy: 56.44444444444444%\n",
      "[[22 89]\n",
      " [16 98]]\n",
      "QDA Accuracy: 53.333333333333336%\n",
      "102 102 (99196, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\scipy\\signal\\spectral.py:1966: UserWarning: nperseg = 256 is greater than input length  = 250, using nperseg = 250\n",
      "  .format(nperseg, input_length))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 16)\n",
      "end\n",
      "start\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 16)\n",
      "end\n",
      "start\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 16)\n",
      "end\n",
      "stat_features_4 shape=(250, 72)\n",
      "stat_features_5 shape=(250, 72)\n",
      "stat_features_6 shape=(250, 72)\n",
      "(750, 72)\n",
      "(750,)\n",
      "...printing seassion_data_4 accuracy.....................\n",
      "[[20 20]\n",
      " [15 20]]\n",
      "Linear SVM Accuracy: 53.333333333333336%\n",
      "[[21 19]\n",
      " [14 21]]\n",
      "RBF SVM Accuracy: 56.00000000000001%\n",
      "[[18 22]\n",
      " [15 20]]\n",
      "RF Accuracy: 50.66666666666667%\n",
      "[[19 21]\n",
      " [13 22]]\n",
      "LDA Accuracy: 54.666666666666664%\n",
      "[[20 20]\n",
      " [11 24]]\n",
      "DT Accuracy: 58.666666666666664%\n",
      "[[19 21]\n",
      " [14 21]]\n",
      "NB Accuracy: 53.333333333333336%\n",
      "[[22 18]\n",
      " [18 17]]\n",
      "KNN Accuracy: 52.0%\n",
      "[[40  0]\n",
      " [35  0]]\n",
      "GPC Accuracy: 53.333333333333336%\n",
      "[[22 18]\n",
      " [18 17]]\n",
      "AdaBoost Accuracy: 52.0%\n",
      "[[14 26]\n",
      " [ 8 27]]\n",
      "QDA Accuracy: 54.666666666666664%\n",
      "\n",
      "\n",
      "\n",
      "...printing seassion_data_5 accuracy.....................\n",
      "[[19 21]\n",
      " [11 24]]\n",
      "Linear SVM Accuracy: 57.333333333333336%\n",
      "[[16 24]\n",
      " [11 24]]\n",
      "RBF SVM Accuracy: 53.333333333333336%\n",
      "[[21 19]\n",
      " [15 20]]\n",
      "RF Accuracy: 54.666666666666664%\n",
      "[[19 21]\n",
      " [16 19]]\n",
      "LDA Accuracy: 50.66666666666667%\n",
      "[[16 24]\n",
      " [11 24]]\n",
      "DT Accuracy: 53.333333333333336%\n",
      "[[10 30]\n",
      " [ 1 34]]\n",
      "NB Accuracy: 58.666666666666664%\n",
      "[[19 21]\n",
      " [19 16]]\n",
      "KNN Accuracy: 46.666666666666664%\n",
      "[[40  0]\n",
      " [35  0]]\n",
      "GPC Accuracy: 53.333333333333336%\n",
      "[[22 18]\n",
      " [13 22]]\n",
      "AdaBoost Accuracy: 58.666666666666664%\n",
      "[[22 18]\n",
      " [11 24]]\n",
      "QDA Accuracy: 61.33333333333333%\n",
      "\n",
      "\n",
      "\n",
      "...printing seassion_data_6 accuracy.....................\n",
      "[[20 20]\n",
      " [13 22]]\n",
      "Linear SVM Accuracy: 56.00000000000001%\n",
      "[[22 18]\n",
      " [10 25]]\n",
      "RBF SVM Accuracy: 62.66666666666667%\n",
      "[[24 16]\n",
      " [14 21]]\n",
      "RF Accuracy: 60.0%\n",
      "[[18 22]\n",
      " [ 8 27]]\n",
      "LDA Accuracy: 60.0%\n",
      "[[19 21]\n",
      " [21 14]]\n",
      "DT Accuracy: 44.0%\n",
      "[[12 28]\n",
      " [ 0 35]]\n",
      "NB Accuracy: 62.66666666666667%\n",
      "[[22 18]\n",
      " [16 19]]\n",
      "KNN Accuracy: 54.666666666666664%\n",
      "[[40  0]\n",
      " [35  0]]\n",
      "GPC Accuracy: 53.333333333333336%\n",
      "[[18 22]\n",
      " [22 13]]\n",
      "AdaBoost Accuracy: 41.333333333333336%\n",
      "[[20 20]\n",
      " [12 23]]\n",
      "QDA Accuracy: 57.333333333333336%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "...printing final_session_data_accuracy\n",
      "[[44 67]\n",
      " [38 76]]\n",
      "Linear SVM Accuracy: 53.333333333333336%\n",
      "[[63 48]\n",
      " [53 61]]\n",
      "RBF SVM Accuracy: 55.111111111111114%\n",
      "[[63 48]\n",
      " [51 63]]\n",
      "RF Accuracy: 56.00000000000001%\n",
      "[[42 69]\n",
      " [44 70]]\n",
      "LDA Accuracy: 49.77777777777778%\n",
      "[[59 52]\n",
      " [56 58]]\n",
      "DT Accuracy: 52.0%\n",
      "[[37 74]\n",
      " [45 69]]\n",
      "NB Accuracy: 47.11111111111111%\n",
      "[[61 50]\n",
      " [61 53]]\n",
      "KNN Accuracy: 50.66666666666667%\n",
      "[[111   0]\n",
      " [114   0]]\n",
      "GPC Accuracy: 49.333333333333336%\n",
      "[[60 51]\n",
      " [43 71]]\n",
      "AdaBoost Accuracy: 58.22222222222222%\n",
      "[[39 72]\n",
      " [34 80]]\n",
      "QDA Accuracy: 52.888888888888886%\n"
     ]
    }
   ],
   "source": [
    "root_path = 'C:/Users/tutan/Bi_Color/data_' \n",
    "\n",
    "model_test_for_sessions_together(root_path,1,2,3)\n",
    "model_test_for_sessions_together(root_path,4,5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f481d99a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9632\\267723634.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstat_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'session_data' is not defined"
     ]
    }
   ],
   "source": [
    "stat_features = extract_features(session_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70af188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
