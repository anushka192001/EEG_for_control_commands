{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Complete.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGOOfGiyQQAw"
      },
      "source": [
        "import csv\n",
        "import pywt\n",
        "import pyedflib\n",
        "import numpy as np\n",
        "from spectrum import *\n",
        "from os import listdir\n",
        "from nitime import utils\n",
        "import scipy.stats as sp\n",
        "from os.path import isfile, join\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy.signal import argrelextrema\n",
        "import tqdm\n",
        "\n",
        "\n",
        "from nitime.viz import plot_tseries\n",
        "from nitime import algorithms as alg\n",
        "from nitime.timeseries import TimeSeries\n",
        "from tqdm import tqdm as tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHKFsl0ok459"
      },
      "source": [
        "!pip install spectrum\n",
        "!pip install pyedflib\n",
        "!pip install utils\n",
        "!pip install nitime\n",
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1lOoW2bLt34"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efBLt4b8jGtS"
      },
      "source": [
        "#from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "#drive.mount('/content/drive') #remove the hash when running code first time\n",
        "\n",
        "#import pandas as pd\n",
        "import pickle\n",
        "DATA_PATH = \"Your data path\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLjYGl3gxHc_"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-uDAe0sxHc_"
      },
      "source": [
        "import glob\n",
        "allFiles = glob.glob(DATA_PATH + \"/*.dat\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMydNcyZxHdA"
      },
      "source": [
        "import sys\n",
        "reload(sys)\n",
        "sys.setdefaultencoding('utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhHBHxCOSny-"
      },
      "source": [
        "import glob\n",
        "allFiles = glob.glob(DATA_PATH + \"/*.dat\")\n",
        "s_music = []\n",
        "x=[]\n",
        "for file_ in allFiles:\n",
        "    df = open(file_,'rb')\n",
        "    s_music.append(df)\n",
        "for i in range(0,32):\n",
        "  x.append(i)\n",
        "  x[i]= pickle.load(s_music[i])\n",
        "sun = []\n",
        "moon = []\n",
        "for i in range(0,32) :\n",
        "  for j in range(0, 40):\n",
        "    sun.append(pd.DataFrame(x[i]['data'][j]))\n",
        "    moon.append(pd.DataFrame(x[i]['labels'][j]).T)\n",
        "    #s_music_label.append(pd.DataFrame(x[i]['labels'][j]).T)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ercreLgXQXyl"
      },
      "source": [
        "def coeff_var(a):\n",
        "    b = a #Extracting the data from the 32 channels\n",
        "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
        "    k = 0; #For counting the current row no.\n",
        "    for i in b:\n",
        "        mean_i = np.mean(i) #Saving the mean of array i\n",
        "        std_i = np.std(i) #Saving the standard deviation of array i\n",
        "        output[k] = std_i/mean_i #computing coefficient of variation\n",
        "        k=k+1\n",
        "    return np.sum(output)/32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKQgVpapQX4B"
      },
      "source": [
        "import heapq\n",
        "from scipy.signal import argrelextrema\n",
        "\n",
        "\n",
        "def first_diff(i):\n",
        "    b=i    \n",
        "    \n",
        "    out = np.zeros(len(b))\n",
        "    \n",
        "    for j in range(len(i)):\n",
        "        out[j] = b[j-1]-b[j]# Obtaining the 1st Diffs\n",
        "        \n",
        "        j=j+1\n",
        "        c=out[1:len(out)]\n",
        "    return c #returns first diff\n",
        "\n",
        "\n",
        "def slope_mean(p):\n",
        "    b = p #Extracting the data from the 32 channels\n",
        "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
        "    res = np.zeros(len(b)-1)\n",
        "    \n",
        "    k = 0; #For counting the current row no.\n",
        "    for i in b:\n",
        "        x=i\n",
        "        amp_max = i[argrelextrema(x, np.greater)[0]]\n",
        "        t_max = argrelextrema(x, np.greater)[0]\n",
        "        amp_min = i[argrelextrema(x, np.less)[0]]\n",
        "        t_min = argrelextrema(x, np.less)[0]\n",
        "        t = np.concatenate((t_max,t_min),axis=0)\n",
        "        t.sort()#sort on the basis of time\n",
        "\n",
        "        h=0\n",
        "        amp = np.zeros(len(t))\n",
        "        res = np.zeros(len(t)-1)\n",
        "        for l in range(len(t)):\n",
        "            amp[l]=i[t[l]]\n",
        "           \n",
        "        \n",
        "        amp_diff = first_diff(amp)\n",
        "        \n",
        "        t_diff = first_diff(t)\n",
        "        \n",
        "        for q in range(len(amp_diff)):\n",
        "            res[q] = amp_diff[q]/t_diff[q]         \n",
        "        output[k] = np.mean(res) \n",
        "        k=k+1\n",
        "    return np.sum(output)/32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE9GrPsnQX_2"
      },
      "source": [
        "import heapq\n",
        "from scipy.signal import argrelextrema\n",
        "\n",
        "\n",
        "def first_diff(i):\n",
        "    b=i    \n",
        "    \n",
        "    out = np.zeros(len(b))\n",
        "    \n",
        "    for j in range(len(i)):\n",
        "        out[j] = b[j-1]-b[j]# Obtaining the 1st Diffs\n",
        "        \n",
        "        j=j+1\n",
        "        c=out[1:len(out)]\n",
        "    return c #returns first diff\n",
        "\n",
        "\n",
        "def slope_var(p):\n",
        "    b = p #Extracting the data from the 32 channels\n",
        "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
        "    res = np.zeros(len(b)-1)\n",
        "    \n",
        "    k = 0; #For counting the current row no.\n",
        "    for i in b:\n",
        "        x=i\n",
        "        amp_max = i[argrelextrema(x, np.greater)[0]]#storing maxima value\n",
        "        t_max = argrelextrema(x, np.greater)[0]#storing time for maxima\n",
        "        amp_min = i[argrelextrema(x, np.less)[0]]#storing minima value\n",
        "        t_min = argrelextrema(x, np.less)[0]#storing time for minima value\n",
        "        t = np.concatenate((t_max,t_min),axis=0) #making a single matrix of all matrix\n",
        "        t.sort() #sorting according to time\n",
        "\n",
        "        h=0\n",
        "        amp = np.zeros(len(t))\n",
        "        res = np.zeros(len(t)-1)\n",
        "        for l in range(len(t)):\n",
        "            amp[l]=i[t[l]]\n",
        "           \n",
        "        \n",
        "        amp_diff = first_diff(amp)\n",
        "        \n",
        "        t_diff = first_diff(t)\n",
        "        \n",
        "        for q in range(len(amp_diff)):\n",
        "            res[q] = amp_diff[q]/t_diff[q] #calculating slope        \n",
        "    \n",
        "        output[k] = np.var(res) \n",
        "        k=k+1#counting k\n",
        "    return np.sum(output)/32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy9k_2jIQYG8"
      },
      "source": [
        "def kurtosis(a):\n",
        "    b = a # Extracting the data from the 32 channels\n",
        "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 32)\n",
        "    k = 0; # For counting the current row no.\n",
        "    for i in b:\n",
        "        mean_i = np.mean(i) # Saving the mean of array i\n",
        "        std_i = np.std(i) # Saving the standard deviation of array i\n",
        "        t = 0.0\n",
        "        for j in i:\n",
        "            t += (pow((j-mean_i)/std_i,4)-3)\n",
        "        kurtosis_i = t/len(i) # Formula: (1/N)*(summation(x_i-mean)/standard_deviation)^4-3\n",
        "        output[k] = kurtosis_i # Saving the kurtosis in the array created\n",
        "        k +=1 # Updating the current row no.\n",
        "    return np.sum(output)/32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKC3SRJkQYNT"
      },
      "source": [
        "def secDiffMean(a):\n",
        "    b = a # Extracting the data of the 32 channels\n",
        "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 32)\n",
        "    temp1 = np.zeros(len(b[0])-1) # To store the 1st Diffs\n",
        "    k = 0; # For counting the current row no.\n",
        "    for i in b:\n",
        "        t = 0.0\n",
        "        for j in range(len(i)-1):\n",
        "            temp1[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
        "        for j in range(len(i)-2):\n",
        "            t += abs(temp1[j+1]-temp1[j]) # Summing the 2nd Diffs\n",
        "        output[k] = t/(len(i)-2) # Calculating the mean of the 2nd Diffs\n",
        "        k +=1 # Updating the current row no.\n",
        "    return np.sum(output)/32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu7moPQdQYUM"
      },
      "source": [
        "def secDiffMax(a):\n",
        "    b = a # Extracting the data from the 32 channels\n",
        "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 32)\n",
        "    temp1 = np.zeros(len(b[0])-1) # To store the 1st Diffs\n",
        "    k = 0; # For counting the current row no.\n",
        "    t = 0.0\n",
        "    for i in b:\n",
        "        for j in range(len(i)-1):\n",
        "            temp1[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
        "        t = temp1[1] - temp1[0]\n",
        "        for j in range(len(i)-2):\n",
        "            if abs(temp1[j+1]-temp1[j]) > t :\n",
        "                t = temp1[j+1]-temp1[j] # Comparing current Diff with the last updated Diff Max\n",
        "\n",
        "        output[k] = t # Storing the 2nd Diff Max for channel k\n",
        "        k +=1 # Updating the current row no.\n",
        "    return np.sum(output)/32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B9jhElcQYaI"
      },
      "source": [
        "def skewness(arr):\n",
        "    data = arr \n",
        "    skew_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
        "    index = 0; #current cell position in the output array\n",
        "   \n",
        "    for i in data:\n",
        "        skew_array[index]=sp.stats.skew(i,axis=0,bias=True)\n",
        "        index+=1 #updating the cell position\n",
        "    return np.sum(skew_array)/32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yIh0yWtQYhN"
      },
      "source": [
        "\n",
        "def first_diff_mean(arr):\n",
        "    data = arr \n",
        "    diff_mean_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
        "    index = 0; #current cell position in the output array\n",
        "   \n",
        "    for i in data:\n",
        "        sum=0.0#initializing the sum at the start of each iteration\n",
        "        for j in range(len(i)-1):\n",
        "            sum += abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
        "           \n",
        "        diff_mean_array[index]=sum/(len(i)-1)\n",
        "        index+=1 #updating the cell position\n",
        "    return np.sum(diff_mean_array)/32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiDOn-w1QYfL"
      },
      "source": [
        "def first_diff_max(arr):\n",
        "    data = arr \n",
        "    diff_max_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
        "    first_diff = np.zeros(len(data[0])-1)#Initialinling the array as all 0s \n",
        "    index = 0; #current cell position in the output array\n",
        "   \n",
        "    for i in data:\n",
        "        max=0.0#initializing at the start of each iteration\n",
        "        for j in range(len(i)-1):\n",
        "            first_diff[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
        "            if first_diff[j]>max: \n",
        "                max=first_diff[j] # finding the maximum of the first differences\n",
        "        diff_max_array[index]=max\n",
        "        index+=1 #updating the cell position\n",
        "    return np.sum(diff_max_array)/32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrojRrcRIIdr"
      },
      "source": [
        "def fractal_dimension(Z, threshold=0.9):\n",
        "\n",
        "    # Only for 2d image\n",
        "    assert(len(Z.shape) == 2)\n",
        "\n",
        "    # From https://github.com/rougier/numpy-100 (#87)\n",
        "    def boxcount(Z, k):\n",
        "        S = np.add.reduceat(\n",
        "            np.add.reduceat(Z, np.arange(0, Z.shape[0], k), axis=0),\n",
        "                               np.arange(0, Z.shape[1], k), axis=1)\n",
        "\n",
        "        # We count non-empty (0) and non-full boxes (k*k)\n",
        "        return len(np.where((S > 0) & (S < k*k))[0])\n",
        "\n",
        "\n",
        "    # Transform Z into a binary array\n",
        "    Z = (Z < threshold)\n",
        "\n",
        "    # Minimal dimension of image\n",
        "    p = min(Z.shape)\n",
        "\n",
        "    # Greatest power of 2 less than or equal to p\n",
        "    n = 2**np.floor(np.log(p)/np.log(2))\n",
        "\n",
        "    # Extract the exponent\n",
        "    n = int(np.log(n)/np.log(2))\n",
        "\n",
        "    # Build successive box sizes (from 2**n down to 2**1)\n",
        "    sizes = 2**np.arange(n, 1, -1)\n",
        "\n",
        "    # Actual box counting with decreasing size\n",
        "    counts = []\n",
        "    for size in sizes:\n",
        "        counts.append(boxcount(Z, size))\n",
        "\n",
        "    # Fit the successive log(sizes) with log (counts)\n",
        "    coeffs = np.polyfit(np.log(sizes), np.log(counts), 1)\n",
        "    return -coeffs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kBvyUNxIJOq"
      },
      "source": [
        "#autogressiveModelParametersBurg\n",
        "\n",
        "def autogressiveModelParametersBurg(labels):\n",
        "    feature = []\n",
        "    a1=[]\n",
        "    a2=[]\n",
        "    a3=[]\n",
        "    model_order = 3\n",
        "    for i in range(32):\n",
        "        AR, rho, ref = arburg(labels[i], model_order)\n",
        "        feature.append(AR);\n",
        "    for i in range(32):\n",
        "        a1.append(feature[i][0])\n",
        "        a2.append(feature[i][1])\n",
        "        a3.append(feature[i][2])\n",
        "        \n",
        "    \n",
        "    ar1=np.mean(a1).real\n",
        "    ar2=np.mean(a2).real \n",
        "    ar3=np.mean(a3).real\n",
        "    \n",
        "    br1=np.min(a1).real\n",
        "    br2=np.min(a2).real \n",
        "    br3=np.min(a3).real\n",
        "    \n",
        "    cr1=np.max(a1).real\n",
        "    cr2=np.max(a2).real \n",
        "    cr3=np.max(a3).real\n",
        "    \n",
        "    \n",
        "    \n",
        "    return ar1,ar2,ar3,br1,br2,br3,cr1,cr2,cr3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XVhUZMwfEAZ"
      },
      "source": [
        "#hjorth(3 feature)\n",
        "\n",
        "def hjorth(input):                                             # function for hjorth \n",
        "    realinput = input\n",
        "    hjorth_activity = np.zeros(len(realinput))\n",
        "    hjorth_mobility = np.zeros(len(realinput))\n",
        "    hjorth_diffmobility = np.zeros(len(realinput))\n",
        "    hjorth_complexity = np.zeros(len(realinput))\n",
        "    diff_input = np.diff(realinput)\n",
        "    diff_diffinput = np.diff(diff_input)\n",
        "    k = 0\n",
        "    for j in realinput:\n",
        "        hjorth_activity[k] = np.var(j)\n",
        "        hjorth_mobility[k] = np.sqrt(np.var(diff_input[k])/hjorth_activity[k])\n",
        "        hjorth_diffmobility[k] = np.sqrt(np.var(diff_diffinput[k])/np.var(diff_input[k]))\n",
        "        hjorth_complexity[k] = hjorth_diffmobility[k]/hjorth_mobility[k]\n",
        "        k = k+1\n",
        "    return np.sum(hjorth_activity)/32, np.sum(hjorth_mobility)/32, np.sum(hjorth_complexity)/32                       #returning hjorth activity, hjorth mobility , hjorth complexity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSwLHX_BhKQS"
      },
      "source": [
        "#maxPwelch\n",
        "\n",
        "from scipy import signal\n",
        "\n",
        "def maxPwelch(data_win,Fs):\n",
        " \n",
        "    \n",
        "    BandF = [0.1, 3, 7, 12, 30]\n",
        "    PMax = np.zeros([32,(len(BandF)-1)]);\n",
        "    \n",
        "    for j in range(32):\n",
        "        f,Psd = signal.welch(data_win[j,:], Fs)\n",
        "        \n",
        "        for i in range(len(BandF)-1):\n",
        "            fr = np.where((f>BandF[i]) & (f<=BandF[i+1]))\n",
        "            PMax[j,i] = np.max(Psd[fr])\n",
        "    \n",
        "    return np.sum(PMax[:,0])/32,np.sum(PMax[:,1])/32,np.sum(PMax[:,2])/32,np.sum(PMax[:,3])/32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRL3KYpYifCl"
      },
      "source": [
        "#wavelet_features\n",
        "\n",
        "import pywt\n",
        "def wavelet_features(epoch,channels):\n",
        "    cA_values = []\n",
        "    cD_values = []\n",
        "    cA_mean = []\n",
        "    cA_std = []\n",
        "    cA_Energy =[]\n",
        "    cD_mean = []\n",
        "    cD_std = []\n",
        "    cD_Energy = []\n",
        "    Entropy_D = []\n",
        "    Entropy_A = []\n",
        "    wfeatures = []\n",
        "    for i in range(channels):\n",
        "        cA,cD=pywt.dwt(epoch[i,:],'coif1')\n",
        "        cA_values.append(cA)\n",
        "        cD_values.append(cD)\t\t#calculating the coefficients of wavelet transform.\n",
        "    for x in range(channels):   \n",
        "        cA_mean.append(np.mean(cA_values[x]))\n",
        "        #wfeatures.append(np.mean(cA_values[x]))\n",
        "        \n",
        "        cA_std.append(abs(np.std(cA_values[x])))\n",
        "        #wfeatures.append(abs(np.std(cA_values[x])))\n",
        "        \n",
        "        cA_Energy.append(abs(np.sum(np.square(cA_values[x]))))\n",
        "        #wfeatures.append(abs(np.sum(np.square(cA_values[x]))))\n",
        "        \n",
        "        cD_mean.append(np.mean(cD_values[x]))\t\t# mean and standard deviation values of coefficents of each channel is stored .\n",
        "        #wfeatures.append(np.mean(cD_values[x]))\n",
        "\n",
        "        cD_std.append(abs(np.std(cD_values[x])))\n",
        "        #wfeatures.append(abs(np.std(cD_values[x])))\n",
        "        \n",
        "        cD_Energy.append(abs(np.sum(np.square(cD_values[x]))))\n",
        "        #wfeatures.append(abs(np.sum(np.square(cD_values[x]))))\n",
        "        \n",
        "        Entropy_D.append(abs(np.sum(np.square(cD_values[x]) * np.log(np.square(cD_values[x])))))\n",
        "        #wfeatures.append(abs(np.sum(np.square(cD_values[x]) * np.log(np.square(cD_values[x])))))\n",
        "        \n",
        "        Entropy_A.append(abs(np.sum(np.square(cA_values[x]) * np.log(np.square(cA_values[x]))))) \n",
        "        #wfeatures.append(abs(np.sum(np.square(cA_values[x]) * np.log(np.square(cA_values[x])))))\n",
        "        \n",
        "    a1=np.mean(cA_mean)\n",
        "    b1=np.mean(cA_std) \n",
        "    c1=np.mean(cA_Energy)  \n",
        "    d1=np.mean(cD_mean)\n",
        "    e1=np.mean(cD_std)  \n",
        "    f1=np.mean(cD_Energy)\n",
        "    g1=np.mean(Entropy_D)\n",
        "    h1=np.mean(Entropy_A)\n",
        "    \n",
        "    a2=np.min(cA_mean)\n",
        "    b2=np.min(cA_std) \n",
        "    c2=np.min(cA_Energy)  \n",
        "    d2=np.min(cD_mean)\n",
        "    e2=np.min(cD_std)  \n",
        "    f2=np.min(cD_Energy)\n",
        "    g2=np.min(Entropy_D)\n",
        "    h2=np.min(Entropy_A)\n",
        "    \n",
        "    a3=np.max(cA_mean)\n",
        "    b3=np.max(cA_std) \n",
        "    c3=np.max(cA_Energy)  \n",
        "    d3=np.max(cD_mean)\n",
        "    e3=np.max(cD_std)  \n",
        "    f3=np.max(cD_Energy)\n",
        "    g3=np.max(Entropy_D)\n",
        "    h3=np.max(Entropy_A)\n",
        "  \n",
        "    \n",
        "    return a1,a2,a3,b1,b2,b3,c1,c2,c3,d1,d2,d3,e1,e2,e3,f1,f2,f3,g1,g2,g3,h1,h2,h3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96EXZ3r_Ur7x"
      },
      "source": [
        "final = pd.DataFrame()\n",
        "for k in range(1280):\n",
        "  rows1=sun[k]\n",
        "  sigbufs=rows1.values\n",
        "  sigbufs.shape\n",
        "  df = pd.DataFrame(columns=['coeff_var'])\n",
        "\n",
        "\n",
        "  #coeff_var-------------------------------------\n",
        "  feature=[]\n",
        "  for i in tqdm(np.arange(0,63,3)):\n",
        "      epoch = sigbufs[0:32,i*128:(i+3)*128]\n",
        "      feature.append(coeff_var(epoch))  \n",
        "  df['coeff_var'] = feature \n",
        "\n",
        "  #fractal_dimension-------------------------------------\n",
        "  feature=[]\n",
        "  for i in tqdm(np.arange(0,63,3)):\n",
        "      epoch = sigbufs[0:32,i*128:(i+3)*128]\n",
        "      feature.append(fractal_dimension(epoch))  \n",
        "  df['fractal_dimension'] = feature \n",
        "\n",
        "\n",
        "  #kurtosis--------------------------------------\n",
        "  feature=[]\n",
        "  for i in tqdm(np.arange(0,63,3)):\n",
        "      epoch = sigbufs[0:32,i*128:(i+3)*128]\n",
        "      feature.append(kurtosis(epoch))\n",
        "  df['kurtosis'] = feature\n",
        "\n",
        "\n",
        "  #secDiffMean-----------------------------------\n",
        "  feature=[]\n",
        "  for i in tqdm(np.arange(0,63,3)):\n",
        "      epoch = sigbufs[0:32,i*128:(i+3)*128]\n",
        "      feature.append(secDiffMean(epoch))\n",
        "  df['secDiffMean'] = feature\n",
        "\n",
        "\n",
        "  #secDiffMax------------------------------------\n",
        "  feature=[]\n",
        "  for i in tqdm(np.arange(0,63,3)):\n",
        "      epoch = sigbufs[0:32,i*128:(i+3)*128]\n",
        "      feature.append(secDiffMax(epoch))\n",
        "  df['secDiffMax'] = feature\n",
        "\n",
        "\n",
        "  #skewness--------------------------------------\n",
        "  feature=[]\n",
        "  for i in tqdm(np.arange(0,63,3)):\n",
        "      epoch = sigbufs[0:32,i*128:(i+3)*128]\n",
        "      feature.append(skewness(epoch))\n",
        "  df['skewness'] = feature\n",
        "\n",
        "\n",
        "  #first_diff_mean------------------------------\n",
        "  feature=[]\n",
        "  for i in tqdm(np.arange(0,63,3)):\n",
        "      epoch = sigbufs[0:32,i*128:(i+3)*128]\n",
        "      feature.append(first_diff_mean(epoch))\n",
        "  df['first_diff_mean'] = feature\n",
        "\n",
        "\n",
        "  #first_diff_max-------------------------------\n",
        "  feature=[]\n",
        "  for i in tqdm(np.arange(0,63,3)):\n",
        "      epoch = sigbufs[0:32,i*128:(i+3)*128]\n",
        "      feature.append(first_diff_max(epoch))\n",
        "  df['first_diff_max'] = feature\n",
        "\n",
        "\n",
        "  #autogressiveModelParametersBurg--------------\n",
        "  a1=[]\n",
        "  a2=[]\n",
        "  a3=[]\n",
        "  b1=[]\n",
        "  b2=[]\n",
        "  b3=[]\n",
        "  c1=[]\n",
        "  c2=[]\n",
        "  c3=[]\n",
        "\n",
        "  for i in tqdm(np.arange(0,63,3)):\n",
        "    epoch = sigbufs[0:32:,i*128:(i+3)*128]\n",
        "    aa1,aa2,aa3,bb1,bb2,bb3,cc1,cc2,cc3=autogressiveModelParametersBurg(epoch)\n",
        "    a1.append(aa1)\n",
        "    b1.append(bb1)\n",
        "    c1.append(cc1)\n",
        "    a2.append(aa2)\n",
        "    b2.append(bb2)\n",
        "    c2.append(cc2)\n",
        "    a3.append(aa3)\n",
        "    b3.append(bb3)\n",
        "    c3.append(cc3)\n",
        "\n",
        "  df['AR1_mean']=a1\n",
        "  df['AR1_min']=b1\n",
        "  df['AR1_max']=c1\n",
        "\n",
        "  df['AR2_mean']=a2\n",
        "  df['AR2_min']=b2\n",
        "  df['AR2_max']=c2\n",
        "\n",
        "  df['AR3_mean']=a3\n",
        "  df['AR3_min']=b3\n",
        "  df['AR3_max']=c3\n",
        "\n",
        "\n",
        "  #hjorth----------------------------------------------------------\n",
        "  a1=[]\n",
        "  b1=[]\n",
        "  c1=[]\n",
        "\n",
        "  for i in tqdm(np.arange(0,63,3)):\n",
        "    epoch = sigbufs[0:32:,i*128:(i+3)*128]\n",
        "    a,b,c=hjorth(epoch)\n",
        "    a1.append(a)\n",
        "    b1.append(b)\n",
        "    c1.append(c)\n",
        "  df['hjorth_activity']=a1\n",
        "  df['hjorth_mobility']=b1\n",
        "  df['hjorth_complexity']=c1\n",
        "\n",
        "\n",
        "  #maxPwelch-----------------------------------------------\n",
        "  a1=[]\n",
        "  b1=[]\n",
        "  c1=[]\n",
        "  d1=[]\n",
        "  e1=[]\n",
        "  f1=[]\n",
        "  g1=[]\n",
        "  h1=[]\n",
        "\n",
        "  for i in tqdm(np.arange(0,63,3)):\n",
        "    epoch = sigbufs[0:32:,i*128:(i+3)*128]\n",
        "    a,b,c,d=maxPwelch(epoch,128)\n",
        "    e=a/b\n",
        "    f=a/c\n",
        "    g=b/d\n",
        "    h=(a+b)/(c)\n",
        "    a1.append(a)\n",
        "    b1.append(b)\n",
        "    c1.append(c)\n",
        "    d1.append(d)\n",
        "    e1.append(e)\n",
        "    f1.append(f)\n",
        "    g1.append(g)\n",
        "    h1.append(h)\n",
        "\n",
        "\n",
        "  df['PMax1']=a1\n",
        "  df['PMax2']=b1\n",
        "  df['PMax3']=c1\n",
        "  df['PMax4']=d1\n",
        "  df['PRatio1']=e1\n",
        "  df['PRatio2']=f1\n",
        "  df['PRatio3']=g1\n",
        "  df['PRatio4']=h1\n",
        "\n",
        "\n",
        "  #wavelet_features-------------------------------------------\n",
        "  a1=[]\n",
        "  a2=[]\n",
        "  a3=[]\n",
        "  b1=[]\n",
        "  b2=[]\n",
        "  b3=[]\n",
        "  c1=[]\n",
        "  c2=[]\n",
        "  c3=[]\n",
        "  d1=[]\n",
        "  d2=[]\n",
        "  d3=[]\n",
        "  e1=[]\n",
        "  e2=[]\n",
        "  e3=[]\n",
        "  f1=[]\n",
        "  f2=[]\n",
        "  f3=[]\n",
        "  g1=[]\n",
        "  g2=[]\n",
        "  g3=[]\n",
        "  h1=[]\n",
        "  h2=[]\n",
        "  h3=[]\n",
        "\n",
        "  for i in tqdm(np.arange(0,63,3)):\n",
        "    epoch = sigbufs[0:32,i*128:(i+3)*128]\n",
        "    aa1,aa2,aa3,bb1,bb2,bb3,cc1,cc2,cc3,dd1,dd2,dd3,ee1,ee2,ee3,ff1,ff2,ff3,gg1,gg2,gg3,hh1,hh2,hh3=wavelet_features(epoch,32)\n",
        "    a1.append(aa1)\n",
        "    b1.append(bb1)\n",
        "    c1.append(cc1)\n",
        "    d1.append(dd1)\n",
        "    e1.append(ee1)\n",
        "    f1.append(ff1)\n",
        "    g1.append(gg1)\n",
        "    h1.append(hh1)\n",
        "    a2.append(aa2)\n",
        "    b2.append(bb2)\n",
        "    c2.append(cc2)\n",
        "    d2.append(dd2)\n",
        "    e2.append(ee2)\n",
        "    f2.append(ff2)\n",
        "    g2.append(gg2)\n",
        "    h2.append(hh2)\n",
        "    a3.append(aa3)\n",
        "    b3.append(bb3)\n",
        "    c3.append(cc3)\n",
        "    d3.append(dd3)\n",
        "    e3.append(ee3)\n",
        "    f3.append(ff3)\n",
        "    g3.append(gg3)\n",
        "    h3.append(hh3)\n",
        "\n",
        "  df['cA_mean_mean']=a1\n",
        "  df['cA_mean_min']=a2\n",
        "  df['cA_mean_max']=a3\n",
        "\n",
        "  df['cA_std_mean']=b1\n",
        "  df['cA_std_min']=b2\n",
        "  df['cA_std_max']=b3\n",
        "\n",
        "  df['cA_Energy_mean']=c1\n",
        "  df['cA_Energy_min']=c2\n",
        "  df['cA_Energy_max']=c3\n",
        "\n",
        "  df['cD_mean_mean']=d1\n",
        "  df['cD_mean_min']=d2\n",
        "  df['cD_mean_max']=d3\n",
        "\n",
        "  df['cD_std_mean']=e1\n",
        "  df['cD_std_min']=e2\n",
        "  df['cD_std_max']=e3\n",
        "\n",
        "  df['cD_Energy_mean']=f1\n",
        "  df['cD_Energy_min']=f2\n",
        "  df['cD_Energy_max']=f3\n",
        "\n",
        "  df['Entropy_D_mean']=g1\n",
        "  df['Entropy_D_min']=g2\n",
        "  df['Entropy_D_max']=g3\n",
        "\n",
        "  df['Entropy_A_mean']=h1\n",
        "  df['Entropy_A_min']=h2\n",
        "  df['Entropy_A_max']=h3\n",
        "\n",
        "\n",
        "  #target\n",
        "  df['valence']=moon[k][0][0]\n",
        "  df['arousal']=moon[k][1][0]\n",
        "  df['dominance']=moon[k][2][0]\n",
        "  df['liking']=moon[k][3][0]\n",
        "  final = pd.concat([final,df])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Tb8TKXYmBrV"
      },
      "source": [
        "pd.DataFrame(final).to_csv('complete.csv')\n",
        "from google.colab import files\n",
        "files.download(\"complete.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZE3YIo2viCI"
      },
      "source": [
        "final.shape()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60Jcz58P7kzS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUi5paIo_FPe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}